{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b063b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import math\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "862ec669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining data parsing functions\n",
    "\n",
    "def find_dataset(path):\n",
    "    with open(path) as file:\n",
    "        data = json.load(file)\n",
    "        return data\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "labels = []\n",
    "responses = []\n",
    "\n",
    "def prep_data(path):\n",
    "    \"\"\"\n",
    "    :returns: training_sentences, training_labels, responses(list), labels, num_classes\n",
    "    \"\"\"\n",
    "    data = find_dataset(path=path)\n",
    "\n",
    "    for intent in data['intents']:\n",
    "        for pattern in intent['patterns']:\n",
    "            training_sentences.append(pattern)\n",
    "            training_labels.append(intent['tag'])\n",
    "        responses.append(intent['responses'])\n",
    "        \n",
    "        if intent['tag'] not in labels:\n",
    "            labels.append(intent['tag'])\n",
    "\n",
    "    num_classes = len(labels)\n",
    "\n",
    "    return training_sentences, training_labels, responses, labels, num_classes, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "341359d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences, training_labels, responses, labels, num_classes, data = prep_data('data/data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84499e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b2c33bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels Dict:\n",
      " {'today': 0, 'song': 1, 'some': 2, 'know': 3, 'thanks': 4, 'free': 5, 'humidity': 6, 'x': 7, 'jot': 8, 'day': 9, 'you': 10, 'lol': 11, 'it': 12, 'hop': 13, 'provide': 14, 'are': 15, 'abiliti': 16, 'how': 17, 'write': 18, 'y': 19, 'see': 20, 'awome': 21, 'amaz': 22, 'sdf': 23, 'there': 24, 'work': 25, 'hehe': 26, 'happy': 27, 'was': 28, 'hey': 29, 'tell': 30, 'z': 31, 'later': 32, 'epic': 33, 'latt': 34, 'jazz': 35, 'should': 36, 'whats': 37, 'like': 38, 'glad': 39, 'do': 40, 'me': 41, 'hi': 42, 'joke': 43, 'who': 44, 'the': 45, 'xyz': 46, 'name': 47, 'good': 48, 'crack': 49, 'bye': 50, 'hello': 51, 'super': 52, 'wake': 53, 'this': 54, 'up': 55, 'from': 56, 'did': 57, 'am': 58, 'your': 59, 'a': 60, 'thank': 61, 'haha': 62, 'give': 63, 'call': 64, 'temperature': 65, 'talk': 66, 'howdy': 67, 'music': 68, 'humid': 69, 'time': 70, 'youtube': 71, 'thats': 72, 'when': 73, 'on': 74, 'whom': 75, 'i': 76, 'news': 77, 'what': 78, 'lmao': 79, 'where': 80, 'recent': 81, 'cool': 82, 'rain': 83, 'laugh': 84, 'again': 85, 'chill': 86, 'is': 87, 'will': 88, 'down': 89, 'hip': 90, 'hobbi': 91, 'in': 92, 'to': 93, 'be': 94, 'note': 95, 'leav': 96, 'so': 97, 'great': 98, 'play': 99, 'can': 100, 'weather': 101, 'lofi': 102, 'make': 103, 'have': 104}\n",
      "Yshape: \n",
      " (105, 20)\n",
      "Ydict: \n",
      " {'greeting': 5, 'goodbye': 11, 'hru': 16, 'wrud': 17, 'name': 22, 'thank': 24, 'comment': 26, 'happiness': 33, 'random': 41, 'info': 55, 'memorize': 57, 'news': 63, 'jotnote': 72, 'youtube': 78, 'lofi': 83, 'weather': 89, 'joke': 92, 'cud': 96, 'chat1': 98, 'blank': 104}\n",
      "Y: \n",
      " [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# defining Preprocessing Class\n",
    "\n",
    "class Preprocess:\n",
    "    \"\"\"\n",
    "    Preprocessing Module by Shakhyar, github: https://github.com/shakhyar\n",
    "    \n",
    "    Preprocessing class like tensorflow's preprocessing module\n",
    "    This Preprocessing module doesn't take the help of any third party libraries\n",
    "    so you have to convert your x and y vector to numpy array later\n",
    "    \n",
    "    All methods accept a 2D python list and not numpy array for simplicity\n",
    "    \n",
    "    If you want to encode a 1D Y vector to its indexes, use the encode_y_to_idx() method\n",
    "    \n",
    "    Propoer preprocessing method for text data:\n",
    "    1: tokenize\n",
    "    2: stem/lemmanize\n",
    "    3: encode\n",
    "    4: pad\n",
    "    \n",
    "    #!NOTE:store the max padding length from _pad2d(), and pass it to _pad1d during inference\n",
    "    #! to match the training shape(but put the output value inside [] if trained on 2d data)\n",
    "    \"\"\"\n",
    "    def _tokenize2d(self, arr):\n",
    "        \"\"\"\n",
    "        expects a 2d array\n",
    "        [\n",
    "        ['s', 'e', 'r']\n",
    "        ]\n",
    "        \"\"\"\n",
    "        self.x = [sentence.split() for sentence in arr]\n",
    "        return self.x\n",
    "    \n",
    "    \n",
    "    def _pad2d(self, arr, max_len):\n",
    "        \"\"\"\n",
    "        Expects a 2d tokenized array only\n",
    "        Return: padded_sequence, max padding length\n",
    "        sample:\n",
    "        [\n",
    "        [4, 3]\n",
    "        [2, 1, 7]\n",
    "        ]\n",
    "        \"\"\"\n",
    "        self.max_len = max_len\n",
    "        self.padded = []\n",
    "        for i in arr:\n",
    "            self.l = len(i)\n",
    "            if self.l>self.max_len:\n",
    "                self.max_len = self.l\n",
    "            \n",
    "        for x in arr:\n",
    "            self.p = []\n",
    "            self.l = len(x)\n",
    "            if self.l < self.max_len:\n",
    "                for _ in range(self.max_len - self.l):\n",
    "                    x.append(0)\n",
    "                self.padded.append(x)\n",
    "            \n",
    "        # store the max_len to later use it to pad input for inference\n",
    "        return self.padded, self.max_len\n",
    "    \n",
    "    def _pad1d(self, arr, max_len):\n",
    "        \"\"\"\n",
    "        expected 1D tokenized array:\n",
    "        ['x', 'y']\n",
    "        and max_len = the maximum padding length from the 2D padded array \n",
    "        \"\"\"\n",
    "        self.l = len(arr)\n",
    "        if self.l < max_len:\n",
    "            for _ in range(max_len - self.l):\n",
    "                arr.append(0)\n",
    "                    \n",
    "        return arr\n",
    "    \n",
    "    \n",
    "    def stem2d(self, arr):\n",
    "        \"\"\"\n",
    "        expected arr:\n",
    "        [\n",
    "        [\"x\", \"y\"],\n",
    "        [\"z\", \"p\", \"e\"]\n",
    "        ...\n",
    "        ]\n",
    "        \"\"\"\n",
    "        self.stems = [[re.sub(r\"\"\"\n",
    "        less|ship|ing|les|ly|es|ed|er\n",
    "        \"\"\", '', word) for word in sentence] for sentence in arr]\n",
    "        return self.stems\n",
    "    \n",
    "    \n",
    "    def lblenc2d(self, arr, min_max_scaler=False):\n",
    "        \"\"\"\n",
    "        arr: any 2D array expected, \n",
    "        min_max_scaler: is set to False, Change it to True if required\n",
    "        \n",
    "        Return: Encoded sequence, labels dict for decoding\n",
    "        \"\"\"\n",
    "        self.labels = {}\n",
    "        self.l = []\n",
    "        self.sequenced = []\n",
    "        for i in range(len(arr)):\n",
    "            for r in arr[i]:\n",
    "                self.l.append(r)\n",
    "                \n",
    "        self.l = set(self.l)\n",
    "    \n",
    "        if min_max_scaler:\n",
    "            for idx, wr in enumerate(self.l):\n",
    "                self.labels[wr] = idx/1000\n",
    "                \n",
    "        else:\n",
    "            for idx, wr in enumerate(self.l):\n",
    "                self.labels[wr] = idx\n",
    "        \n",
    "        for z in arr:\n",
    "            wr_ch = []\n",
    "            for wr in z:\n",
    "                if wr in self.labels:\n",
    "                    wr_ch.append(self.labels[wr])\n",
    "\n",
    "            self.sequenced.append(wr_ch)\n",
    "    \n",
    "        print(\"Labels Dict:\\n\",self.labels)\n",
    "        pickle.dump(self.labels, open('saved/labels_dict.p', 'wb'))\n",
    "        \n",
    "        return self.sequenced\n",
    "    \n",
    "#############################################################################    \n",
    "    def encode_y_to_idx(self, y_1D, max_len=20, padding=False):\n",
    "        self._y = []\n",
    "        self.yd = {}\n",
    "        \n",
    "        for idx, el in enumerate(y_1D):\n",
    "            self.yd[el] = idx\n",
    "            \n",
    "        for idx, el in enumerate(y_1D):\n",
    "            self.lbl_pd = []\n",
    "            self.lbl_pd.append(self.yd[el])\n",
    "            for _ in range(max_len-1):\n",
    "                self.lbl_pd.append(0)\n",
    "                \n",
    "            self._y.append(self.lbl_pd)\n",
    "        self._y = np.array(self._y)\n",
    "        print(\"Yshape: \\n\",self._y.shape)\n",
    "        print(\"Ydict: \\n\",self.yd)\n",
    "        print(\"Y: \\n\",self._y)\n",
    "        return self._y\n",
    "            \n",
    "##############################################################################        \n",
    "    def preprocess_wrap(self, x, y, min_max_scaler=False, max_len=20):\n",
    "        \"\"\"\n",
    "        Return: x, y and max padding length\n",
    "       \n",
    "        to customize it in your code, use the following lines:\n",
    "        x = module._tokenize2d(x)\n",
    "        x = module.stem2d(x)\n",
    "        x = module.lblenc2d(x, min_max_scaler=True/False)\n",
    "        x, max_len = module._pad2d(self.x)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.x = self.lblenc2d(self.stem2d(self._tokenize2d(x)), min_max_scaler=min_max_scaler)\n",
    "        self.x, self.max_len = self._pad2d(self.x, max_len=max_len)\n",
    "        \n",
    "        self.y = self.encode_y_to_idx(y)\n",
    "        \n",
    "        return self.x, self.y, self.max_len\n",
    "    \n",
    "    \n",
    "p = Preprocess()\n",
    "\n",
    "x, y, max_len = p.preprocess_wrap(training_sentences, training_labels, min_max_scaler=False)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0bfb1686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([72,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f4923efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activations:\n",
    "    def __init__(self):\n",
    "        self.e = 2.71828\n",
    "        \n",
    "    def cosh(self, x):\n",
    "        self.z = (self.e**x + self.e**-x)/2\n",
    "        return self.z\n",
    "    \n",
    "    def sech(self, x):\n",
    "        return 1/self.cosh(x)\n",
    "        \n",
    "    def gelu(self, x):\n",
    "        return np.tanh(x)\n",
    "        \"\"\"\n",
    "        self.l = []\n",
    "        for ar in x:\n",
    "            self.n_s = []\n",
    "            for el in ar:\n",
    "                self.n_s.append(0.5*el*(1 + math.tanh(math.sqrt(2/math.pi)*(el + 0.044715*el**3))))\n",
    "            self.l.append(self.n_s)\n",
    "        return np.array(self.l)\"\"\"\n",
    "\n",
    "    def gelu_derivative(self, x):\n",
    "        return 1-np.tanh(x)**2\n",
    "        \"\"\"\n",
    "        self.l = []\n",
    "        for ar in x:\n",
    "            self.n_s = []\n",
    "            for el in ar:\n",
    "                self.n_s.append(0.5*math.tanh(0.0356774*el**3 + 0.797885*el) \n",
    "                           + (0.0535161*el**3 + 0.398942*el) \n",
    "                *self.sech(0.0356774*el**3 + 0.797885*el)**2 + 0.5)\n",
    "            \n",
    "            self.l.append(self.n_s)\n",
    "        return np.array(self.l)\"\"\"\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        return np.exp(x)/sum(np.exp(x))\n",
    "\n",
    "    \n",
    "    def one_hot(self, Y):\n",
    "        \"\"\"\n",
    "        this method was inspired from Samson Zhang's YT video, titled:\n",
    "        \"Building a neural network FROM SCRATCH (no Tensorflow/Pytorch, just numpy & math)\"\n",
    "        link: https://youtu.be/w8yWXqWQYmU?t=1157\n",
    "        \n",
    "        \"\"\"\n",
    "        self.Y = np.array(Y)\n",
    "        print(self.Y.shape)\n",
    "        self.one_hot_Y = np.zeros((self.Y.size, self.Y.max()+1))\n",
    "        self.one_hot_Y[np.arange(self.Y.size), self.Y] = 1\n",
    "        print(self.one_hot_Y.shape)\n",
    "        return np.squeeze(np.asarray(self.one_hot_Y))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d4a99cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "[37 37 37 37 37 37 37 37 32 32 32 32 32 32 32 32 32 32 32 32] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.0\n",
      "Iteration:  10\n",
      "[103 103 103 103 103 103 103   2   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.6\n",
      "Iteration:  20\n",
      "[ 64  64  64  64  64  83 103   2   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.6\n",
      "Iteration:  30\n",
      "[27 27 27 27 27 29 34  2  0  0  0  0  0  0  0  0  0  0  0  0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.6\n",
      "Iteration:  40\n",
      "[4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.65\n",
      "Iteration:  50\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  60\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  70\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  80\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  90\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  100\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  110\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  120\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  130\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\romoni gogoi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: overflow encountered in exp\n",
      "c:\\users\\romoni gogoi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in true_divide\n",
      "c:\\users\\romoni gogoi\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: overflow encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 140\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  150\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  160\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  170\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  180\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  190\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  200\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  210\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  220\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  230\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  240\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  250\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  260\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  270\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  280\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  290\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  300\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  310\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  320\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  330\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  340\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  350\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  360\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  370\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  380\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  390\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  400\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  410\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  420\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  430\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  440\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  450\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  460\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  470\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  480\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n",
      "Iteration:  490\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] [[  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " [  5   0   0 ...   0   0   0]\n",
      " ...\n",
      " [104   0   0 ...   0   0   0]\n",
      " [104   0   0 ...   0   0   0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [104   0   0 ...   0   0   0]]\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "class NN(Activations):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.w1 = np.random.rand(output_size, input_size)\n",
    "        self.b1 = np.random.rand(output_size, 1)\n",
    "        self.w2 = np.random.rand(output_size, output_size)\n",
    "        self.b2 = np.random.rand(output_size, 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, w1, b1, w2, b2, _input):\n",
    "        self.input = _input\n",
    "        self.z0 = np.dot(w1, self.input) + b1\n",
    "        self.a0 = self.gelu(self.z0)\n",
    "        self.z1 = np.dot(w2, self.a0) + b2\n",
    "        self.a1 = self.softmax(self.z1)\n",
    "        \n",
    "        return self.z0, self.a0, self.z1, self.a1\n",
    "\n",
    "    def back_prop(self, z0, a0, z1, a1, w1, w2, x, y):\n",
    "        #self.one_hot_y = self.one_hot(y)\n",
    "        #print(self.one_hot_y.shape)\n",
    "        self.m, self.n = y.shape\n",
    "        self.dv_z1 = a0 - y # work left = edit params with self and finish\n",
    "        self.dv_w2 = 1 / self.m * self.dv_z1.dot(a0.T)\n",
    "        self.dv_b2 = 1 / self.m * np.sum(self.dv_z1)\n",
    "        self.dv_z0 = w2.T.dot(self.dv_z1) * self.gelu_derivative(z0)\n",
    "        self.dv_w1 = 1 / self.m * self.dv_z0.dot(x.T)\n",
    "        self.dv_b1 = 1 / self.m * np.sum(self.dv_z0)\n",
    "        return self.dv_w1, self.dv_b1, self.dv_w2, self.dv_b2\n",
    "    \n",
    "    def update_params(self, w1, b1, w2, b2, dv_w1, dv_b1, dv_w2, dv_b2, a):\n",
    "        self.w1 = self.w1 - a * dv_w1\n",
    "        self.b1 = self.b1 - a * dv_b1    \n",
    "        self.w2 = self.w2 - a * dv_w2  \n",
    "        self.b2 = self.b2 - a * dv_b2    \n",
    "        return self.w1, self.b1, self.w2, self.b2\n",
    "    \n",
    "    def get_accuracy(self, y_hat, y):\n",
    "        return np.sum(y_hat == y) / y.size\n",
    "\n",
    "    def gradient_descent(self, x, y, alpha, epochs):\n",
    "        for i in range(epochs):\n",
    "            self.z0, self.a0, self.z1, self.a1 = self.forward(self.w1, self.b1, self.w2, self.b2, x)\n",
    "            #print(self.z0.shape, self.a0.shape, self.z1.shape, self.a1.shape)\n",
    "            self.dv_w1, self.dv_b1, self.dv_w2, self.dv_b2 = self.back_prop(self.z0,\n",
    "                                                                           self.a0, \n",
    "                                                                           self.z1, \n",
    "                                                                           self.a1, \n",
    "                                                                           self.w1, self.w2, x, y)\n",
    "            #print(self.dv_w1.shape, self.dv_b1.shape, self.dv_w2.shape, self.dv_b2.shape)\n",
    "            #print(alpha)\n",
    "            self.w1, self.b1, self.w2, self.b2 = self.update_params(self.w1, self.b1, \n",
    "                                                                    self.w2, self.b2, \n",
    "                                                                    self.dv_w1, self.dv_b1,\n",
    "                                                                    self.dv_w2, self.dv_b2, 0.3)\n",
    "            if i % 10 == 0:\n",
    "                print(\"Iteration: \", i)\n",
    "                self.y_hat = self.get_y_hat(self.a1)\n",
    "                print(self.y_hat, y)\n",
    "                print(self.get_accuracy(self.y_hat, y))\n",
    "        \n",
    "        return self.w1, self.b1, self.w2, self.b2\n",
    "\n",
    "    def get_y_hat(self, a1):\n",
    "        #print(a1)\n",
    "        return np.argmax(a1, 0)\n",
    "    \n",
    "    def predict(self, x, w1, b1, w2, b2):\n",
    "        _, _, _, self.a1 = self.forward(w1, b1, w2, b2, x)\n",
    "        self.y_pred = self.get_y_hat(self.a1)\n",
    "        return self.y_pred\n",
    "    \n",
    "model = NN(len(training_sentences), len(training_labels))\n",
    "W1, b1, W2, b2 = model.gradient_descent(np.array(x), y, alpha=0.3, epochs=500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c3ed4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['greeting',\n",
       " 'greeting',\n",
       " 'greeting',\n",
       " 'greeting',\n",
       " 'greeting',\n",
       " 'greeting',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'goodbye',\n",
       " 'hru',\n",
       " 'hru',\n",
       " 'hru',\n",
       " 'hru',\n",
       " 'hru',\n",
       " 'wrud',\n",
       " 'name',\n",
       " 'name',\n",
       " 'name',\n",
       " 'name',\n",
       " 'name',\n",
       " 'thank',\n",
       " 'thank',\n",
       " 'comment',\n",
       " 'comment',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'random',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'info',\n",
       " 'memorize',\n",
       " 'memorize',\n",
       " 'news',\n",
       " 'news',\n",
       " 'news',\n",
       " 'news',\n",
       " 'news',\n",
       " 'news',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'jotnote',\n",
       " 'youtube',\n",
       " 'youtube',\n",
       " 'youtube',\n",
       " 'youtube',\n",
       " 'youtube',\n",
       " 'youtube',\n",
       " 'lofi',\n",
       " 'lofi',\n",
       " 'lofi',\n",
       " 'lofi',\n",
       " 'lofi',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'weather',\n",
       " 'joke',\n",
       " 'joke',\n",
       " 'joke',\n",
       " 'cud',\n",
       " 'cud',\n",
       " 'cud',\n",
       " 'cud',\n",
       " 'chat1',\n",
       " 'chat1',\n",
       " 'blank',\n",
       " 'blank',\n",
       " 'blank',\n",
       " 'blank',\n",
       " 'blank',\n",
       " 'blank']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "967c1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(20, 1) -0.5\n",
    "w = np.random.rand(20, 105) -0.5\n",
    "b = np.random.rand(7, 1) -0.5\n",
    "\n",
    "z = np.dot(np.squeeze(np.asarray(x)), w) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72db7b19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 20)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((105, 20)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce93d405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00135081, -0.0063563 , -0.05167706, ..., -0.03448022,\n",
       "        -0.03351578, -0.01717697],\n",
       "       [ 0.00652018, -0.01305005,  0.24821286, ...,  0.10523572,\n",
       "         0.13576983,  0.0183976 ],\n",
       "       [-0.04903455,  0.33451576, -0.01667384, ...,  0.06630084,\n",
       "         0.02652709,  0.00278336],\n",
       "       ...,\n",
       "       [-0.05188661,  0.18294188,  0.10132879, ...,  0.24121708,\n",
       "        -0.05144671,  0.03756235],\n",
       "       [ 0.06480318,  0.31617693,  0.04467178, ...,  0.10143641,\n",
       "         0.2718432 ,  0.10435436],\n",
       "       [-0.01404002,  0.16085825,  0.33582808, ...,  0.06614964,\n",
       "         0.27989019, -0.04757342]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gelu(x):\n",
    "    l = []\n",
    "    for ar in x:\n",
    "        n_s = []\n",
    "        for el in ar:\n",
    "            n_s.append(0.5*el*(1 + math.tanh(math.sqrt(2/math.pi)*(el + 0.044715*el**3))))\n",
    "        l.append(n_s)\n",
    "    return l\n",
    "\n",
    "np.array(gelu(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4863147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.49783976, 0.48975236, 0.40972354, ..., 0.44167093, 0.44340072,\n",
       "        0.47180591],\n",
       "       [0.51029806, 0.47872753, 0.79071765, ..., 0.64492585, 0.68013515,\n",
       "        0.52853151],\n",
       "       [0.41477555, 0.85933109, 0.47265498, ..., 0.59603811, 0.5406418 ,\n",
       "        0.50442201],\n",
       "       ...,\n",
       "       [0.40932056, 0.72987368, 0.64023182, ..., 0.78459518, 0.4101661 ,\n",
       "        0.55662981],\n",
       "       [0.59405869, 0.84575944, 0.56666868, ..., 0.64036173, 0.81074471,\n",
       "        0.64387083],\n",
       "       [0.47707599, 0.70724711, 0.86028277, ..., 0.59583862, 0.81734187,\n",
       "        0.41754572]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cosh(x):\n",
    "    e = 2.71828\n",
    "    z = (e**x + e**-x)/2\n",
    "    return z\n",
    "\n",
    "def sech(x):\n",
    "    return 1/cosh(x)\n",
    "\n",
    "def gelu_derivative(x):\n",
    "    l = []\n",
    "    for ar in x:\n",
    "        n_s = []\n",
    "        for el in ar:\n",
    "            n_s.append(0.5*math.tanh(0.0356774*el**3 + 0.797885*el) \n",
    "                       + (0.0535161*el**3 + 0.398942*el) \n",
    "            *sech(0.0356774*el**3 + 0.797885*el)**2 + 0.5)\n",
    "            \n",
    "        l.append(n_s)\n",
    "    return l\n",
    "\n",
    "np.array(gelu_derivative(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33535ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00270747 -0.01284422 -0.11363487 ... -0.07323608 -0.07105672\n",
      "  -0.03535084]\n",
      " [ 0.01290743 -0.02666745  0.38249245 ...  0.1836982   0.22978135\n",
      "   0.03577428]\n",
      " [-0.10722489  0.48702945 -0.03428539 ...  0.12095675  0.05098131\n",
      "   0.00554222]\n",
      " ...\n",
      " [-0.11414656  0.29667748  0.17761813 ...  0.37361073 -0.11307297\n",
      "   0.07109519]\n",
      " [ 0.11843987  0.46551939  0.08375329 ...  0.17778621  0.41200189\n",
      "   0.18233048]\n",
      " [-0.02873894  0.26594575  0.48855575 ...  0.12070303  0.42188705\n",
      "  -0.10371392]]\n"
     ]
    }
   ],
   "source": [
    "np.place(w, w<=0 , 0.3*(np.exp(w)-1))\n",
    "        \n",
    "print(w)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d9fb5797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
